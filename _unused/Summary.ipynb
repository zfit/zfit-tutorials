{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# The zfit package\n",
    "\n",
    "Currently, the functionality of the zfit package is two-fold: design a high-level API to manage model building, fitting and generation, and implement this API using the `tensorflow` backend.\n",
    "\n",
    "The final goal is to be able to, given a PDF model `pdf`, a dataset `data`, and a list of `params` to minimize, perform minimization tasks such as\n",
    "\n",
    "```python\n",
    "from zfit.minimize import Minuit\n",
    "\n",
    "nll = zfit.unbinned_nll(pdf, data, norm_range=(-10, 10))\n",
    "minimizer = Minuit()\n",
    "minimizer.minimize(nll, params)\n",
    "minimizer.hesse(params)\n",
    "minimizer.error(params)\n",
    "result = minimizer.get_state()\n",
    "```\n",
    "\n",
    "and generation in a very simple way\n",
    "\n",
    "```python\n",
    "sample = pdf.sample(n_draws=int(1e7), limits=(-10, 10))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "The main concepts in the API are\n",
    "  - Parameters\n",
    "  - PDFs (for the time being, let's consider scalar functions as unnormalized PDFs)\n",
    "  - Minimizers\n",
    "\n",
    "In the following, we informally outline the basics of each of these objects, but we will not go into some of the more nitty-gritty API details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Parameters are named quantities to be optimized in the minimization problems we are trying to solve.\n",
    "Classes implementing parameters contain the value of the parameter, its limits, whether it's fixed or not, and eventually symmetric and asymmetric errors.\n",
    "\n",
    "\n",
    "A *Parameter* initialization **MUST** contain its name and its initial value, and **MAY** include its lower and upper limits.\n",
    "\n",
    "One can access the parameter information through the following properties (names are self explanatory):\n",
    "  - Values are `init_value` are `fitted_value`.\n",
    "  - Name is accessed through `name`.\n",
    "  - Errors are `error`, `upper_error` and `lower_error`, and raise an error if one tries to access them without having performed a minimization first.\n",
    "\n",
    "Additionally, the parameter can be fixed/unfixed setting the `floating` flag to either True or False.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs\n",
    "\n",
    "PDF objects are normalized distributions, typically as a function of several parameters.\n",
    "A very important concept is the *normalization range*, which is mandatory in most operations involving PDFs.\n",
    "\n",
    "*Note*: details on how to compose and create your own PDFs, implement integrals, etc, belong to the implementation and will be discussed later.\n",
    "\n",
    "PDF objects **MUST** be initialized giving their named parameters, and **MAY** also have a name. For example:\n",
    "\n",
    "```python\n",
    "gauss = zfit.pdf.Gauss(mu=mu, sigma=sigma, name=\"My Gaussian\")\n",
    "```\n",
    "\n",
    "The main methods of the PDF are then\n",
    "\n",
    "- Getting the probability through the `probs` method, which **MUST** be called with a data array `x` and a normalization range `norm_range` as inputs. For example:\n",
    "\n",
    "    ```\n",
    "    # Get the probabilities of some random generated events\n",
    "    probs = gauss.prob(x=np.random.random(10), norm_range=(-30., 30))\n",
    "    ```\n",
    "- there **MUST** be the option to *temporarely* set the norm_range of a pdf with a contextmanager.**(ALBERT: mention it? ok?)**\n",
    "\n",
    "    ```python\n",
    "    with pdf.temp_norm_range((1, 5)):\n",
    "        pdf.prob(data)  # norm_range is now set\n",
    "     ```\n",
    "\n",
    "- Getting the value of its integral in some given `limits`. While the `norm_range` is also mandatory here, it may be requested that this integral is calculated over the unnormalized PDF by setting it to `False`:\n",
    "\n",
    "    ```python\n",
    "    # Calculate the integral between -5 and 3 over the PDF normalized between -30 and 30\n",
    "    integral_norm = gauss.integrate(limits=(-5, 3), norm_range=(-30., 30))\n",
    "    # Calculate the unnormalized integral\n",
    "    integral_unnorm = gauss.integrate(limits=(-5, 3), norm_range=False)\n",
    "    ```\n",
    "\n",
    "- Sampling from the PDF is done through the `sample` method, which **MUST** include the number of events `n_draws` as well as the limits from which to draw (`limits`):\n",
    "\n",
    "    ```python\n",
    "    # Draw 1000 samples within (-10, 10)\n",
    "    sample = gauss.sample(n_draws=1000, limits=(-10, 10))\n",
    "    ```\n",
    "\n",
    "Additionally, extended PDFs, which will result in anything using a `norm_range` to not return the probability but the number probability (the function will be normalized to this yield instead of 1 inside the `norm_range`), can be created through the `set_yield` method, which **MUST** get a parameter as input:\n",
    "\n",
    "```python\n",
    "yield1 = Parameter(\"yield1\", 100, 0, 1000)\n",
    "gauss.set_yield(yield1)\n",
    "# This integral yields approx 100\n",
    "integral_extended = gauss.integrate(limits=(-10, 10), norm_range=(-10, 10))\n",
    "```\n",
    "\n",
    "The `is_extended` property can be then used to check whether a PDF is extended or not.\n",
    "\n",
    "Loss functions can then be build using `pdf.prob`, following a common interface, in which the model, the dataset and the normalization range **MUST** be given, and where parameter constraints in form of a dictionary `{param: constraint}` **MAY** be given.\n",
    "As an example for unbinned NLL (but it's the same for binned NLL, $\\chi^2$, etc), one would write\n",
    "\n",
    "```python\n",
    "my_loss = zfit.unbinned_nll(gauss,\n",
    "                            data,\n",
    "                            norm_range=(-10, 10),\n",
    "                            constraints={})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizers\n",
    "\n",
    "Minimizer objects are key to provide a coherent fitting API.\n",
    "They are tied to a loss function and they keep an internal state that can be queried at any moment.\n",
    "\n",
    "In their initialization, the loss function **MUST** be given. Additionally, the `params` to minimize, the `tolerance`, its `name`, as well as any other arguments needed to configure a particular algorithm **MAY** be given.\n",
    "\n",
    "The API **REQUIRES** to implement the following methods:\n",
    "- `minimize(params)`, which returns an `int` with the status.\n",
    "- `step(params)`, which performs only one step of the minimization procedure. If not applicable, this returns `NotImplementedError`.\n",
    "- `hesse(params)`, which calculates the Hessian.\n",
    "- `error(params)`, which calculates the two-sided error. This typically complicated function can be configured with `set_error_options`. Additionally, several methods for calculating this error can be implemented in a given minimizer, and the `set_error_method` method can be used to set the one called by `error`.\n",
    "- `get_state(copy=True)`, which returns the internal state of the minimizer, *ie*, the parameters, their errors, etc. The optional `copy` parameters controls whether a copy of the internal state (which would be the equivalent of a fit result) is returned, or just a view (reference) of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "zfit implements the above API in pure python based on the `tensorflow` framework.\n",
    "\n",
    "Feature-wise, it adds the capability of building complex models and implementing your own PDFs, some useful functions to make its usage easy, and the possibility of running in a non-eager, advanced mode that allows to take advantage of `tensorflow` graphs.\n",
    "\n",
    "In addition, it aims to implement a large library of distributions wrapping `tensorflow.distributions` plus the addition of specific HEP ones (not only normalized distributions, but also functions such as spin factors or Blatt-Weisskopf barrier factors), and a complete set of minimizers (currently Minuit, `scipy.optimize` and `tensorflow` optimizers).\n",
    "\n",
    "As a general idea, context managers will be also implemented wherever there are repetitive parameters to be used (for example, setting normalization ranges) to allow for cleaner code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll walk through some simple examples to showcase how zfit is implemented and how to use it in a practical way.\n",
    "\n",
    "*Note*: We will run in advanced mode (that is, no eager execution, and thus DAG all `tensorflow` objects are DAGs) to illustrate how `tensorflow` is leveraged behind the scenes.\n",
    "When running in \"normal\" mode, all these complications (such as the use of sessions and delayed execution) will not be there, thus resulting in simpler code. A context manager will be provided to switch to non-eager execution on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import zfit\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Executing eagerly:\", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, let's create a few datasets to play with (*note*: no data helpers have been implemented yet, so it's necessary to use tensorflow directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_at_five = np.random.normal(5.1, 1.2, size=10000)\n",
    "gauss_at_ten = np.random.normal(10.4, 2.3, size=5000)\n",
    "exp = np.random.exponential(10, size=8000)\n",
    "_ = plt.hist(np.concatenate([exp,gauss_at_five,gauss_at_ten]),\n",
    "             bins=50,\n",
    "             range=(0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "ds_gauss_at_five = tf.convert_to_tensor(gauss_at_five)\n",
    "ds_gauss_at_ten = tf.convert_to_tensor(gauss_at_ten)\n",
    "ds_exp = tf.convert_to_tensor(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "Now we can try to fit one of the Gaussians.\n",
    "To do that, we need to create the parameters, instantiate a PDF and run the fitting procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shortcut function will be available in zfit, but here\n",
    "# we use the core one to highlight the use of tensorflow graphs\n",
    "def api_unbinned_nll(pdf, data, norm_range):\n",
    "    return zfit.core.loss.unbinned_nll(pdf.prob(data, norm_range=norm_range))\n",
    "\n",
    "mu1 = zfit.Parameter(\"mu\", 5.0, 0., 10)\n",
    "sigma1 = zfit.Parameter(\"sigma\", 1, 0.1, 5.)\n",
    "gauss1 = zfit.pdf.Gauss(mu=mu1, sigma=sigma1)\n",
    "\n",
    "nll1 = api_unbinned_nll(gauss1, ds_gauss_at_five, (0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from zfit.minimize import Minuit\n",
    "\n",
    "minimizer = Minuit(nll1)\n",
    "# Prepare tensorflow, this will be removed in the future\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "zfit"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
