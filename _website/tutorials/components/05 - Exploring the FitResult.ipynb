{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FitResult\n",
    "\n",
    "In this tutorial, we will explore the `FitResult`of zfit. Specifically, we will examine the error methods hesse and errors as well as attributes like info, valid etc. We will also provide an example with weighted data to demonstrate how FitResult works with weighted datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start out by creating a simple gaussian model and sampling some data from it. We will then fit the data with the same model and explore the `FitResult`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zfit\n",
    "import zfit.z.numpy as znp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = zfit.Space('x', 0, 10)\n",
    "mu = zfit.Parameter('mu', 5, 0, 10)\n",
    "sigma = zfit.Parameter('sigma', 1, 0, 10)\n",
    "nsig = zfit.Parameter('nsig', 1000, 0, 10000)\n",
    "gauss = zfit.pdf.Gauss(obs=obs, mu=mu, sigma=sigma,extended=nsig)\n",
    "data = gauss.sample()\n",
    "print(f\"The sampled data (poisson fluctuated) has {data.nevents} events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an extended likelihood to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = zfit.loss.ExtendedUnbinnedNLL(model=gauss, data=data)\n",
    "minimizer = zfit.minimize.Minuit()\n",
    "result = minimizer.minimize(nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply printing the result will give you a beautified overview of the fit result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened\n",
    "\n",
    "First and foremost, the FitResult contains all the information about what happened with the minimization, most notably the `loss` that was minimized, the `minimizer` that was used and the `params` that were fitted (the latter has a beautified presentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "loss: {result.loss}\n",
    "minimizer: {result.minimizer}\n",
    "params: {result.params}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### params\n",
    "\n",
    "`params` contains all the information of the parameters that was ever added to them. This includes the output of uncertainty methods, limits and much more.\n",
    "The actual content looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"params raw: {repr(result.params)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FitResult` has a lot of attributes and methods. We will now explore some of them.\n",
    "\n",
    "\n",
    "All the displayed information can be accessed via the attributes of the `FitResult` object, namely\n",
    "- valid: whether the fit converged and is in general valid\n",
    "- converged: whether the fit converged\n",
    "- param at limit: whether any parameter is at its limit (approximate, hard to estimate)\n",
    "- edm: estimated distance to minimum\n",
    "- fmin: the minimum of the function, i.e. the negative log likelihood\n",
    "- values: the parameter values at the minimum in an array-like object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "valid: {result.valid}\n",
    "converged: {result.converged}\n",
    "param at limit: {result.params_at_limit}\n",
    "edm: {result.edm}\n",
    "fmin: {result.fmin}\n",
    "optimal values: {result.values}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error methods\n",
    "\n",
    "There are two main ways to estimate the uncertainties: Either using a profiling method that varies the parameters one by one and finds\n",
    "the point of 1 sigma (or the specified n sigma), resulting in asymmetric errors, or using a matrix inversion method that calculates\n",
    "an approximation of the former by using a second derivative matrix.\n",
    "\n",
    "The first method is called `errors` and the second `hesse`. Both methods are available in the `FitResult` object.\n",
    "\n",
    "### Pitfall weights\n",
    "\n",
    "For weighted likelihoods, the `errors` method will not report the correct uncertainties. Instead, `hesse` should be used\n",
    "as it will, by default, calculate the asymptotic correct approximations for weights as we will see a few lines below.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "Both methods take some common arguments:\n",
    "- `params`: the parameters to calculate the errors for. If `None`, all parameters will be used. (this can be expensive!)\n",
    "- `name`: the name of the new result. If `None`, the name will be chosen automatically.\n",
    "- `cl`: the confidence level for the errors. The default is 0.68, which corresponds to 1 sigma.\n",
    "- `method`: the method to use. The default is `None` which will use the default method of the uncertainty estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, new_result = result.errors(name=\"errors\")\n",
    "print(f\"New result: {new_result}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertainties are added to the fit result. The `new_result` is usually `None` but in case a new minimum was found, it will be returned\n",
    "as the new result. In this case, the old result will be rendered invalid.\n",
    "\n",
    "There are currently two implementations, the minos method from `iminuit` (as `minuit_minos`) and a completely independent implementation\n",
    "(`zfit_errors`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More information\n",
    "\n",
    "To find more information about the uncertainty estimation, the return value can be inspected. This is though also automatically added to the result\n",
    "to each parameter. Looking again at the raw `params` attribute, we find that all the information is there:\n",
    "\n",
    "_Note: this part is still under WIP and future plans are to standardize these attributes as well. Any ideas or inputs are very welcome!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"params raw: {repr(result.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors2, _ = result.errors(name=\"zfit_unc\", method=\"zfit_errors\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, they both agree well. We can also change the confidence level to 0.95, which corresponds to 2 sigma and recalculate the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors3, _ = result.errors(name=\"zfit_2sigma\", method=\"zfit_errors\", cl=0.95)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hesse\n",
    "\n",
    "The hesse method approximates the errors by calculating the second derivative matrix of the function and inverting it.\n",
    "As for `errors` there are two implementations, one from `iminuit` (`minuit_hesse`) and one from `zfit` (`hesse_np`).\n",
    "\n",
    "Additionally, the `hesse` has a third option, `approx`: this is the approximation of the hessian estimated by the minimizer\n",
    "during the minimization procedure. This however *can* be `None`! Also, the accuracy can be low, especially if the\n",
    "fit converged rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hesse = result.hesse(name=\"h minuit\", method=\"minuit_hesse\", cl=0.95)  # can also take the cl argument\n",
    "hesse2 = result.hesse(name=\"h zfit\", method=\"hesse_np\")\n",
    "hesse3 = result.hesse(name=\"h approx\", method=\"approx\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, zfit uses by default a numerical approximation of the hessian, which is usually sufficient and good for one-time use.\n",
    "However, if you want to use the hessian for multiple fits, it is recommended to force it to use the exact gradient provided by the\n",
    "backend. To make sure one or the other is used, you can set `zfit.run.set_autograd_mode(False)` or `zfit.run.set_autograd_mode(True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zfit.run.set_autograd_mode(True):\n",
    "    hesse4 = result.hesse(name=\"h autograd\", method=\"hesse_np\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted uncertainties\n",
    "\n",
    "A weighted likelihood is technically not a likelihood anymore and the errors are not calculated correctly. However, the hesse method\n",
    "can be corrected for weights, which is done automatically as soon as the dataset is weighted.\n",
    "\n",
    "The method used is the `asymptotically correct` yet computationally expensive method described in [Parameter uncertainties in weighted unbinned maximum likelihood fits](https://link.springer.com/article/10.1140/epjc/s10052-022-10254-8).\n",
    "\n",
    "The computation involves the jacobian of each event that can be expensive to compute. Again, zfit offers the possibility to use the\n",
    "autograd or the numerical jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_data = zfit.Data.from_tensor(obs=obs, tensor=data.value(), weights=znp.random.uniform(0.1, 5, size=(data.nevents,)))\n",
    "weighted_nll = zfit.loss.UnbinnedNLL(model=gauss, data=weighted_data)\n",
    "weighted_result = minimizer.minimize(weighted_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_result.errors(name=\"errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zfit.run.set_autograd_mode(True):\n",
    "    weighted_result.hesse(name=\"hesse autograd\")\n",
    "    weighted_result.hesse(name=\"hesse autograd np\", method=\"hesse_np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zfit.run.set_autograd_mode(False):\n",
    "    weighted_result.hesse(name=\"hesse numeric\")\n",
    "    weighted_result.hesse(name=\"hesse numeric np\", method=\"hesse_np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_result)  # FIXME: the errors are not correct for the nsig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the errors are underestimated for the nuisance parameters using the minos method while the hesse method is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized minimizer information\n",
    "\n",
    "Some of the minimizers collect information about the loss during the minimization process, such as an approximation of the hessian, inverse hessian, gradient etc. They can be retrieved via `approx`, note however that they can be `None`.\n",
    "\n",
    "`hessian` and `inv_hessian` have an `invert` argument: if True and only one of the two is available, the other one will be inverted to obtain the request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Approx gradient: {result.approx.gradient()}\")  # gradient approx not available in iminuit\n",
    "print(f\"Approx hessian (no invert): {result.approx.hessian(invert=False)}\")  # hessian approximation is also not available\n",
    "print(f\"Approx inverse hessian: {result.approx.inv_hessian(invert=False)}\")  # inv_hessian is available\n",
    "print(f\"Approx hessian (can invert): {result.approx.hessian(invert=True)}\")  # allowing the invert now inverts the inv_hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### info\n",
    "The information returned by the minimizer. CAREFUL! This is a dictionary and can be different for different minimizers. The standardized keys can always be accessed in other ways, such as the approximations of the hessian, the covariance matrix etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.info.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be helpful if underlying information from a specific minimizer should be retrieved. For example, the `original` key contains the original result from the minimizer while \"minuit\" is the actual `iminuit` minimizer that was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.info.get(\"original\", f\"Not available for the minimizer: {result.minimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.info.get(\"minuit\", \"Not available, not iminuit used in minimization?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding problems\n",
    "\n",
    "If the fit failed for some reason, `valid` may be False. To find the actual reason, `message` should be human-readable information about what went wrong. If everything went well, the message will be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
