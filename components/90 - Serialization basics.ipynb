{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialization, loading and saving of zfit objects\n",
    "\n",
    "The long-term goal is to be able to save and load zfit objects, such as models, spaces, parameters, etc. This is not yet fully implemented, but some parts are already available, some stable, some more experimental.\n",
    "\n",
    "Overview:\n",
    "- Binary (pickle) loading and dumping of (frozen) `FitResult` is fully available\n",
    "- Human-readable serialization (also summarized under HS3) of\n",
    " - parameters and models is available, but not yet stable\n",
    " - losses and datasets are not yet available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:44.279440915Z",
     "start_time": "2023-07-04T09:13:44.218982607Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "import mplhep\n",
    "import numpy as np\n",
    "import zfit\n",
    "import zfit.z.numpy as znp\n",
    "from matplotlib import pyplot as plt\n",
    "from zfit import z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:44.344315600Z",
     "start_time": "2023-07-04T09:13:44.224966703Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mu = zfit.Parameter(\"mu\", 1.2, -4, 5)\n",
    "sigma = zfit.Parameter(\"sigma\", 3, 0, 10)\n",
    "obs = zfit.Space(\"obs1\", limits=(-10, 20))\n",
    "model = zfit.pdf.Gauss(mu=mu, sigma=sigma, obs=obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:44.626719682Z",
     "start_time": "2023-07-04T09:13:44.314016788Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = model.sample(10000)\n",
    "loss = zfit.loss.UnbinnedNLL(model=model, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:44.630490029Z",
     "start_time": "2023-07-04T09:13:44.628116302Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "minimizer = zfit.minimize.Minuit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.078062754Z",
     "start_time": "2023-07-04T09:13:44.634012974Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(*obs.limit1d, 1000)\n",
    "mu.set_value(1.5)\n",
    "sigma.set_value(2)\n",
    "mplhep.histplot(data.to_binned(50), density=True, label=\"data\")\n",
    "plt.plot(x, model.pdf(x), label=\"model pre fit\")\n",
    "result = minimizer.minimize(loss)\n",
    "plt.plot(x, model.pdf(x), label=\"model post fit\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.081724535Z",
     "start_time": "2023-07-04T09:13:45.079081658Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result.freeze()\n",
    "dumped_result = pickle.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.089182199Z",
     "start_time": "2023-07-04T09:13:45.084547906Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loaded_result = pickle.loads(dumped_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.286143190Z",
     "start_time": "2023-07-04T09:13:45.089906166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mu.set_value(0.42)\n",
    "print(f\"mu before: {mu.value()}\")\n",
    "zfit.param.set_values(params=model.get_params(), values=loaded_result)\n",
    "print(f\"mu after: {mu.value()}, set to result value: {loaded_result.params[mu]['value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.286381522Z",
     "start_time": "2023-07-04T09:13:45.110205375Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-readable serialization (HS3)\n",
    "\n",
    "**WARNING: this section is unstable and, apart from dumping for publishing on a \"if it works, great\" basis, everything else is recommended for power users only and will surely break in the future.**\n",
    "\n",
    "HS3 is the \"hep-statistics-serialization-standard\", that is currently being developed and aims to provide a human-readable serialization format for loading and dumping of the likelihood. It is not stable and neither is the implementation of it in zfit (which also doesn't follow it strictly for different reasons currently).\n",
    "\n",
    "We can either dump objects in the library directly, or create a complete dump to an HS3-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.287047511Z",
     "start_time": "2023-07-04T09:13:45.151818465Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.287692092Z",
     "start_time": "2023-07-04T09:13:45.195475042Z"
    }
   },
   "outputs": [],
   "source": [
    "mu.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.288178006Z",
     "start_time": "2023-07-04T09:13:45.195679267Z"
    }
   },
   "outputs": [],
   "source": [
    "obs.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the object\n",
    "\n",
    "We can also recreate the object from the dictionary. As a simple example, let's do this for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.288744487Z",
     "start_time": "2023-07-04T09:13:45.195824685Z"
    }
   },
   "outputs": [],
   "source": [
    "gauss2 = model.from_dict(model.to_dict())  # effectively creates a copy (parameters are shared!)\n",
    "gauss2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit of cheating, since we could use the model itself to use the `from_dict` (or more generally, the `from_*` methods). More generally, in this case, we need to know the class of the object (currently) in order to convert it back (this is not the case for the HS3 dumping below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.288945771Z",
     "start_time": "2023-07-04T09:13:45.243618137Z"
    }
   },
   "outputs": [],
   "source": [
    "gauss3 = zfit.pdf.Gauss.from_dict(model.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping and loading\n",
    "\n",
    "These representations can be converted to anything JSON/YAML like. In fact, the objects already offer out-of-the-box some conversion methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.289701922Z",
     "start_time": "2023-07-04T09:13:45.243850081Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.290281402Z",
     "start_time": "2023-07-04T09:13:45.244018144Z"
    }
   },
   "outputs": [],
   "source": [
    "sigma.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing large datasets\n",
    "\n",
    "We can also serialize data objects. However, binned data can be large (i.e. in the millions) and are theferore not suitable to be stored in plain text (which requires typically a factor of 10 more space). Therefore, we can use the `to_asdf` method to store the data in a binary format. This will convert any numpy-array into a binary format while just keeping a reference instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.294861384Z",
     "start_time": "2023-07-04T09:13:45.244174736Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, naturally the whole data array is saved. Trying to convert this to JSON or YAML will fail as these dumpers by default cannot handle numpy arrays (one could convert the numpy arrays to lists, but the problem with space will remain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.307383710Z",
     "start_time": "2023-07-04T09:13:45.287498620Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data.to_json()\n",
    "except TypeError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow the advice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.507248332Z",
     "start_time": "2023-07-04T09:13:45.287858472Z"
    }
   },
   "outputs": [],
   "source": [
    "data_asdf = data.to_asdf()\n",
    "data_asdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASDF format\n",
    "\n",
    "The ASDF format stands for [Advanced Scientific Data Format](https://asdf.readthedocs.io/en/latest/). It is a mixture of yaml and a binary format that can store arbitrary data, including numpy arrays, pandas dataframes, astropy tables, etc.\n",
    "\n",
    "Two attributes are convenient to know:\n",
    " - `tree`: returns the dict representation of the data\n",
    " - `write_to(path)`: writes the data to a file in `path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.554688217Z",
     "start_time": "2023-07-04T09:13:45.499563339Z"
    }
   },
   "outputs": [],
   "source": [
    "data_asdf.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.554984413Z",
     "start_time": "2023-07-04T09:13:45.547805565Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:45.555197569Z",
     "start_time": "2023-07-04T09:13:45.548139660Z"
    }
   },
   "outputs": [],
   "source": [
    "data_asdf.write_to(\"data.asdf\")  # Will create a file in the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the file using the `head` command to printout the first 25 lines (out of a total of about 471!). As we can see, the beginning is a yaml representation of the data, while the end is a binary representation of the data (which produces weird signs). The file is not human-readable, but can be loaded by any ASDF library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:46.272975151Z",
     "start_time": "2023-07-04T09:13:45.548407961Z"
    }
   },
   "outputs": [],
   "source": [
    "!head -25 data.asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.001598595Z",
     "start_time": "2023-07-04T09:13:46.251157486Z"
    }
   },
   "outputs": [],
   "source": [
    "!wc -l data.asdf  # the file is about 471 lines long, filled with binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading can be done using the `asdf` library directly too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.064629808Z",
     "start_time": "2023-07-04T09:13:47.005462375Z"
    }
   },
   "outputs": [],
   "source": [
    "import asdf\n",
    "\n",
    "with asdf.open(\"data.asdf\") as f:\n",
    "    tree = f.tree\n",
    "    data = zfit.Data.from_asdf(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.093193817Z",
     "start_time": "2023-07-04T09:13:47.067703370Z"
    }
   },
   "outputs": [],
   "source": [
    "data.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.094131819Z",
     "start_time": "2023-07-04T09:13:47.082251988Z"
    }
   },
   "outputs": [],
   "source": [
    "# cleanup of the file\n",
    "import pathlib\n",
    "\n",
    "pathlib.Path(\"data.asdf\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS3 serialization\n",
    "\n",
    "To convert our objects into a HS3-like format, we can use the following functions.\n",
    "**The format is not yet stable and will change in the future.**\n",
    "\n",
    "It is therefore recommended to try out: if it works, great. If it errors, fine. Don't expect it to be able to load again in the future, but if it works, it's nice for publication\n",
    "\n",
    "### Objects\n",
    "\n",
    "We can serialize the objects itself, PDFs, spaces etc. The difference to the above mentioned serialization with `to_dict` is that the HS3 serialization is more verbose and contains more information, such as metadata and fields for other objects (e.g. the parameters of a PDF). It will also fill in some of the fields by extracting the information from the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.160512923Z",
     "start_time": "2023-07-04T09:13:47.087043035Z"
    }
   },
   "outputs": [],
   "source": [
    "zfit.hs3.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.172729691Z",
     "start_time": "2023-07-04T09:13:47.127529113Z"
    }
   },
   "outputs": [],
   "source": [
    "hs3obj = zfit.hs3.loads(zfit.hs3.dumps(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.173480212Z",
     "start_time": "2023-07-04T09:13:47.172020303Z"
    }
   },
   "outputs": [],
   "source": [
    "list(hs3obj['distributions'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing\n",
    "\n",
    "While the format is being improved constantly, a likelihood created with this format can in principle be published, maybe alongside the paper. If we may want to omit the data and only publish the model, we can just create a HS3 object with the pdf instead of the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.319939293Z",
     "start_time": "2023-07-04T09:13:47.172476842Z"
    }
   },
   "outputs": [],
   "source": [
    "hs3dumped = zfit.hs3.dumps(model)\n",
    "pprint(hs3dumped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.511521384Z",
     "start_time": "2023-07-04T09:13:47.308345461Z"
    }
   },
   "outputs": [],
   "source": [
    "hs3dumped = zfit.hs3.dumps(loss)\n",
    "pprint(hs3dumped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.543604166Z",
     "start_time": "2023-07-04T09:13:47.535423644Z"
    }
   },
   "outputs": [],
   "source": [
    "hs3dumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T09:13:47.672205748Z",
     "start_time": "2023-07-04T09:13:47.535685300Z"
    }
   },
   "outputs": [],
   "source": [
    "zfit.hs3.loads(hs3dumped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
